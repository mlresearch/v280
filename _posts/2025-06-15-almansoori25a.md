---
title: Collaborative and Efficient Personalization with Mixtures of Adaptors
openreview: 3J6AXM2HfN
abstract: Heterogenous data is prevalent in real-world federated learning. We propose
  a parameter-efficient framework, Federated Low-Rank Adaptive Learning (FLoRAL),
  that allows clients to personalize in groups by mixing between low-rank adaptors,
  where the mixtures are client-specific. FLoRAL is a model parameterization that
  casts personalized federated learning as a multi-task learning problem, with weight
  sharing as an implicit regularizer. It is memory-efficient, as the personalized
  parameters (i.e., base model + adaptors) are all federated. Our results show that
  FLoRAL can generalize better than a mixture of full models when data are scarce.
  It can also consistently personalize better than models with a locally tuned adaptor
  per client. This demonstrates the benefits of "federated personalization" and its
  robustness against overfitting. We derive the convergence rates and show theoretically
  that FLoRAL can lead to better variance reduction of the base model’s gradients.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: almansoori25a
month: 0
tex_title: Collaborative and Efficient Personalization with Mixtures of Adaptors
firstpage: 1328
lastpage: 1364
page: 1328-1364
order: 1328
cycles: false
bibtex_author: Almansoori, Abdulla Jasem and Horv\'{a}th, Samuel and Tak\'{a}\v{c},
  Martin
author:
- given: Abdulla Jasem
  family: Almansoori
- given: Samuel
  family: Horváth
- given: Martin
  family: Takáč
date: 2025-06-15
address:
container-title: Conference on Parsimony and Learning
volume: '280'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 6
  - 15
pdf: https://raw.githubusercontent.com/mlresearch/v280/main/assets/almansoori25a/almansoori25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
