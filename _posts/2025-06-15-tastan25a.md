---
title: 'FedPeWS: Personalized Warmup via Subnetworks for Enhanced Heterogeneous Federated
  Learning'
openreview: iYwiyS1YdQ
abstract: Statistical data heterogeneity is a significant barrier to convergence in
  federated learning (FL). While prior work has advanced heterogeneous FL through
  better optimization objectives, these methods fall short when there is *extreme*
  data heterogeneity among collaborating participants. We hypothesize that convergence
  under extreme data heterogeneity is primarily hindered due to the aggregation of
  conflicting updates from the participants in the initial collaboration rounds. To
  overcome this problem, we propose a warmup phase where each participant learns a
  personalized mask and updates only a subnetwork of the full model. This *personalized
  warmup* allows the participants to focus initially on learning specific *subnetworks*
  tailored to the heterogeneity of their data. After the warmup phase, the participants
  revert to standard federated optimization, where all parameters are communicated.
  We empirically demonstrate that the proposed personalized warmup via subnetworks
  (*FedPeWS*) approach improves accuracy and convergence speed over standard federated
  optimization methods. The code can be found at https://github.com/tnurbek/fedpews.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: tastan25a
month: 0
tex_title: 'FedPeWS: Personalized Warmup via Subnetworks for Enhanced Heterogeneous
  Federated Learning'
firstpage: 462
lastpage: 483
page: 462-483
order: 462
cycles: false
bibtex_author: Tastan, Nurbek and Horv\'{a}th, Samuel and Tak\'{a}\v{c}, Martin and
  Nandakumar, Karthik
author:
- given: Nurbek
  family: Tastan
- given: Samuel
  family: Horváth
- given: Martin
  family: Takáč
- given: Karthik
  family: Nandakumar
date: 2025-06-15
address:
container-title: Conference on Parsimony and Learning
volume: '280'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 6
  - 15
pdf: https://raw.githubusercontent.com/mlresearch/v280/main/assets/tastan25a/tastan25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
