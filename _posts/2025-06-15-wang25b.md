---
title: Concept Bottleneck Model with Zero Performance Loss
openreview: ii2zoKgRJV
abstract: Interpreting machine learning models with high-level, human-understandable
  concepts has gained increasing importance. The concept bottleneck model (CBM) is
  a popular approach for providing such explanations but typically sacrifices some
  prediction power compared with standard black-box models. In this work, we propose
  an approach to turn an off-the-shelf black-box model into a CBM without changing
  its predictions or compromising prediction power. Through an invertible mapping
  from the modelâ€™s latent space to a concept space, predictions are decomposed into
  a linear combination of concepts. This provides concept-based explanations for the
  complex model and allows us to intervene in its predictions manually. Experiments
  across benchmarks demonstrate that CBM-zero provides comparable explainability and
  better accuracy than other CBM methods.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wang25b
month: 0
tex_title: Concept Bottleneck Model with Zero Performance Loss
firstpage: 433
lastpage: 461
page: 433-461
order: 433
cycles: false
bibtex_author: Wang, Zhenzhen and Popel, Aleksander and Sulam, Jeremias
author:
- given: Zhenzhen
  family: Wang
- given: Aleksander
  family: Popel
- given: Jeremias
  family: Sulam
date: 2025-06-15
address:
container-title: Conference on Parsimony and Learning
volume: '280'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 6
  - 15
pdf: https://raw.githubusercontent.com/mlresearch/v280/main/assets/wang25b/wang25b.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
