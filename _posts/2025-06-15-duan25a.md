---
title: Towards Vector Optimization on Low-Dimensional Vector Symbolic Architecture
openreview: '08PRND19BY'
abstract: Vector Symbolic Architecture (VSA) is emerging in machine learning due to
  its efficiency, but they are hindered by issues of hyperdimensionality and accuracy.
  As a promising mitigation, the Low-Dimensional Computing (LDC) method significantly
  reduces the vector dimension by $\sim$100 times while maintaining accuracy, by employing
  a gradient-based optimization.  Despite its potential, LDC optimization for VSA
  is still underexplored. Our investigation into vector updates underscores the importance
  of stable, adaptive dynamics in LDC training. We also reveal the overlooked yet
  critical roles of batch normalization (BN) and knowledge distillation (KD) in standard
  approaches. Besides the accuracy boost, BN does not add computational overhead during
  inference, and KD significantly enhances inference confidence. Through extensive
  experiments and ablation studies across multiple benchmarks, we provide a thorough
  evaluation of our approach and extend the interpretability of binary neural network
  optimization similar to LDC, previously unaddressed in BNN literature.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: duan25a
month: 0
tex_title: Towards Vector Optimization on Low-Dimensional Vector Symbolic Architecture
firstpage: 1413
lastpage: 1432
page: 1413-1432
order: 1413
cycles: false
bibtex_author: Duan, Shijin and Liu, Yejia and Liu, Gaowen and Kompella, Ramana Rao
  and Ren, Shaolei and Xu, Xiaolin
author:
- given: Shijin
  family: Duan
- given: Yejia
  family: Liu
- given: Gaowen
  family: Liu
- given: Ramana Rao
  family: Kompella
- given: Shaolei
  family: Ren
- given: Xiaolin
  family: Xu
date: 2025-06-15
address:
container-title: Conference on Parsimony and Learning
volume: '280'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 6
  - 15
pdf: https://raw.githubusercontent.com/mlresearch/v280/main/assets/duan25a/duan25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
