---
title: 'Dual Reasoning: A GNN-LLM Collaborative Framework for Knowledge Graph Question
  Answering'
openreview: odnOkx8Qfj
abstract: Large Language Models (LLMs) excel at intuitive, implicit reasoning. Guiding
  LLMs to construct thought chains can enhance their deliberate reasoning abilities,
  but also faces challenges such as hallucination. Knowledge Graphs (KGs) can provide
  explicit structured knowledge for LLMs to alleviate these issues. However, existing
  KG-enhanced methods often overlook explicit graph learning, making it challenging
  to efficiently provide precise reasoning chains for LLMs. Following dual-process
  theory, we propose Dual-Reasoning (DualR), a novel framework that integrates an
  external system based on Graph Neural Network (GNN) for explicit reasoning on KGs,
  complementing the implicit reasoning of LLMs through externalized reasoning chains.
  DualR designs an LLM-empowered GNN module for explicit learning on KGs, efficiently
  extracting high-quality reasoning chains. These reasoning chains are then refined
  to a knowledge-enhanced multiple-choice prompt, guiding a frozen LLM to reason thoughtfully
  for final answer determination. Extensive experiments on three benchmark KGQA datasets
  demonstrate that DualR achieves state-of-the-art performance while maintaining high
  efficiency and interpretability.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: liu25b
month: 0
tex_title: 'Dual Reasoning: A GNN-LLM Collaborative Framework for Knowledge Graph
  Question Answering'
firstpage: 351
lastpage: 372
page: 351-372
order: 351
cycles: false
bibtex_author: Liu, Guangyi and Zhang, Yongqi and Li, Yong and Yao, Quanming
author:
- given: Guangyi
  family: Liu
- given: Yongqi
  family: Zhang
- given: Yong
  family: Li
- given: Quanming
  family: Yao
date: 2025-06-15
address:
container-title: Conference on Parsimony and Learning
volume: '280'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 6
  - 15
pdf: https://raw.githubusercontent.com/mlresearch/v280/main/assets/liu25b/liu25b.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
