---
title: Adversarially Robust Spiking Neural Networks with Sparse Connectivity
openreview: VhCOSdgFl2
abstract: Deployment of deep neural networks in resource-constrained embedded systems
  requires innovative algorithmic solutions to facilitate their energy and memory
  efficiency. To further ensure the reliability of these systems against malicious
  actors, recent works have extensively studied adversarial robustness of existing
  architectures. Our work focuses on the intersection of adversarial robustness, memory-
  and energy-efficiency in neural networks. We introduce a neural network conversion
  algorithm designed to produce sparse and adversarially robust spiking neural networks
  (SNNs) by leveraging the sparse connectivity and weights from a robustly pretrained
  artificial neural network (ANN). Our approach combines the energy-efficient architecture
  of SNNs with a novel conversion algorithm, leading to state-of-the-art performance
  with enhanced energy and memory efficiency through sparse connectivity and activations.
  Our models are shown to achieve up to 100x reduction in the number of weights to
  be stored in memory, with an estimated 8.6x increase in energy efficiency compared
  to dense SNNs, while maintaining high performance and robustness against adversarial
  threats.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: schmolli25a
month: 0
tex_title: Adversarially Robust Spiking Neural Networks with Sparse Connectivity
firstpage: 865
lastpage: 883
page: 865-883
order: 865
cycles: false
bibtex_author: Schmolli, Mathias and Baronig, Maximilian and Legenstein, Robert and
  Ozdenizci, Ozan
author:
- given: Mathias
  family: Schmolli
- given: Maximilian
  family: Baronig
- given: Robert
  family: Legenstein
- given: Ozan
  family: Ozdenizci
date: 2025-06-15
address:
container-title: Conference on Parsimony and Learning
volume: '280'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 6
  - 15
pdf: https://raw.githubusercontent.com/mlresearch/v280/main/assets/schmolli25a/schmolli25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
